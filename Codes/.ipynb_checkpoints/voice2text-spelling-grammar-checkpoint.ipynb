{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363e324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording ...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python asr-1.py record myvoice.wav 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755903fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py play myvoice.wav 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c31b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py transcribe myvoice.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000a522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py evaluate myvoice_transcription.txt ground-truth.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6791e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b26ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained spelling correction model and tokenizer\n",
    "spelling_correction = 'oliverguhr/spelling-correction-english-base'\n",
    "spelling_model = AutoModelForSeq2SeqLM.from_pretrained(spelling_correction)\n",
    "spelling_tokenizer = AutoTokenizer.from_pretrained(spelling_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e856d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained grammar correction model and tokenizer\n",
    "grammar_correction = 'vennify/t5-base-grammar-correction'\n",
    "grammar_model = AutoModelForSeq2SeqLM.from_pretrained(grammar_correction)\n",
    "grammar_tokenizer = AutoTokenizer.from_pretrained(grammar_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fd4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correct spelling\n",
    "def correct_spelling(input_text):\n",
    "    sentences = sent_tokenize(input_text)\n",
    "    corrected_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = spelling_tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=spelling_tokenizer.model_max_length)\n",
    "        outputs = spelling_model.generate(**tokens, max_length=spelling_tokenizer.model_max_length)\n",
    "        corrected_sentence = spelling_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "    return ' '.join(corrected_sentences)\n",
    "\n",
    "# Function to correct grammar\n",
    "def correct_grammar(input_text):\n",
    "    tokens = grammar_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=grammar_tokenizer.model_max_length)\n",
    "    outputs = grammar_model.generate(**tokens, max_length=grammar_tokenizer.model_max_length)\n",
    "    return grammar_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Function to correct both spelling and grammar\n",
    "def correct_spelling_and_grammar(input_text):\n",
    "    spelling_corrected = correct_spelling(input_text)\n",
    "    return correct_grammar(spelling_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad73172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input text from file\n",
    "with open('myvoice_transcription.txt', 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read().strip()\n",
    "\n",
    "# Apply corrections\n",
    "spelling_corrected_text = correct_spelling(input_text)\n",
    "grammar_corrected_text = correct_grammar(input_text)\n",
    "combined_corrected_text = correct_spelling_and_grammar(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a04e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " ebarkmentof conservation our foocas is unsustainable leaving a critical aspect of protecting al were planet sustainable leaving involves reducing waste conserving natural resources and making choices that benefit the environment simple actions like recycling using energy efficient appliances and reducing water usage can have a significant impact remember every small step we take towards eqofrontiness contribute to larger global afford in preserving\n",
      "\n",
      "Spelling corrected text:\n",
      " Barkment of conservation our foocas is unsustainable, leaving a critical aspect of protecting all where planet sustainable leaving involves reducing waste, conserving natural resources and making choices that benefit the environment simple actions like recycling using energy efficient appliances and reducing water usage can have a significant impact remember every small step we take towards profitability contribute to larger global afford in preserving.\n",
      "\n",
      "Grammar corrected text:\n",
      " Our environment is unsustainable leaving a critical aspect of protecting our planet sustainable leaving involves reducing waste conserving natural resources and making choices that benefit the environment simple actions like recycling using energy efficient appliances and reducing water usage can have a significant impact remember every small step we take towards eqofrontiness contribute to larger global afford in preserving our planet.\n",
      "\n",
      "Combined spelling and grammar corrected text:\n",
      " Conservation our foocas is unsustainable, leaving a critical aspect of protecting all where planet sustainable leaving involves reducing waste, conserving natural resources and making choices that benefit the environment simple actions like recycling using energy efficient appliances and reducing water usage can have a significant impact remember every small step we take towards profitability contributes to larger global afford in preserving.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\\n\", input_text)\n",
    "print(\"\\nSpelling corrected text:\\n\", spelling_corrected_text)\n",
    "print(\"\\nGrammar corrected text:\\n\", grammar_corrected_text)\n",
    "print(\"\\nCombined spelling and grammar corrected text:\\n\", combined_corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f715c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined corrected text saved to ../Data/myvoice_transcription_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename\n",
    "output_filename = \"../Data/myvoice_transcription_corrected.txt\"\n",
    "\n",
    "# Save the combined corrected text to a file\n",
    "with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(combined_corrected_text)\n",
    "\n",
    "print(f\"Combined corrected text saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a253c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(reference, hypothesis):\n",
    "    r = reference.split()\n",
    "    h = hypothesis.split()\n",
    "    # Building the matrix\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0: \n",
    "                d[0][j] = j\n",
    "            elif j == 0: \n",
    "                d[i][0] = i\n",
    "    # Calculation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    return d[len(r)][len(h)] / float(len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a638dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(reference, hypothesis):\n",
    "    r = reference\n",
    "    h = hypothesis\n",
    "    # Building the matrix\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "    # Calculation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    return d[len(r)][len(h)] / float(len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e023c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text - Word Error Rate: 0.5087719298245614\n",
      "Original Text - Character Error Rate: 0.19390581717451524\n",
      "Spelling Corrected Text - Word Error Rate: 0.453125\n",
      "Spelling Corrected Text - Character Error Rate: 0.15176715176715178\n",
      "Grammar Corrected Text - Word Error Rate: 0.375\n",
      "Grammar Corrected Text - Character Error Rate: 0.14137214137214138\n",
      "Combined Corrected Text - Word Error Rate: 0.421875\n",
      "Combined Corrected Text - Character Error Rate: 0.16216216216216217\n"
     ]
    }
   ],
   "source": [
    "# Read ground truth text from file\n",
    "with open('ground_truth.txt', 'r', encoding='utf-8') as file:\n",
    "    ground_truth_text = file.read().strip()\n",
    "\n",
    "# Calculate WER and CER for spelling-corrected text\n",
    "spelling_wer = calculate_wer(ground_truth_text, spelling_corrected_text)\n",
    "spelling_cer = calculate_cer(ground_truth_text, spelling_corrected_text)\n",
    "\n",
    "# Calculate WER and CER for grammar-corrected text\n",
    "grammar_wer = calculate_wer(ground_truth_text, grammar_corrected_text)\n",
    "grammar_cer = calculate_cer(ground_truth_text, grammar_corrected_text)\n",
    "\n",
    "# Calculate WER and CER for combined corrected text\n",
    "combined_wer = calculate_wer(ground_truth_text, combined_corrected_text)\n",
    "combined_cer = calculate_cer(ground_truth_text, combined_corrected_text)\n",
    "\n",
    "# Read WER and CER from results.json\n",
    "with open('../Data/results.json', 'r', encoding='utf-8') as file:\n",
    "    results_data = json.load(file)\n",
    "\n",
    "original_wer = results_data.get(\"word_error_rate\", \"Not available\")\n",
    "original_cer = results_data.get(\"character_error_rate\", \"Not available\")\n",
    "\n",
    "# Print WER and CER for each type of corrected text\n",
    "print(\"Original Text - Word Error Rate:\", original_wer)\n",
    "print(\"Original Text - Character Error Rate:\", original_cer)\n",
    "print(\"Spelling Corrected Text - Word Error Rate:\", spelling_wer)\n",
    "print(\"Spelling Corrected Text - Character Error Rate:\", spelling_cer)\n",
    "print(\"Grammar Corrected Text - Word Error Rate:\", grammar_wer)\n",
    "print(\"Grammar Corrected Text - Character Error Rate:\", grammar_cer)\n",
    "print(\"Combined Corrected Text - Word Error Rate:\", combined_wer)\n",
    "print(\"Combined Corrected Text - Character Error Rate:\", combined_cer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021d504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
