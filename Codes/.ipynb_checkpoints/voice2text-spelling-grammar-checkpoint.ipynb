{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py record myvoice.wav 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py play myvoice.wav 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfeb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py transcribe myvoice.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py evaluate myvoice_transcription.txt ground-truth.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c3a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load pre-trained spelling correction model and tokenizer\n",
    "spelling_correction = 'oliverguhr/spelling-correction-english-base'\n",
    "spelling_model = AutoModelForSeq2SeqLM.from_pretrained(spelling_correction)\n",
    "spelling_tokenizer = AutoTokenizer.from_pretrained(spelling_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb17509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained grammar correction model and tokenizer\n",
    "grammar_correction = 'vennify/t5-base-grammar-correction'\n",
    "grammar_model = AutoModelForSeq2SeqLM.from_pretrained(grammar_correction)\n",
    "grammar_tokenizer = AutoTokenizer.from_pretrained(grammar_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46511d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correct spelling\n",
    "def correct_spelling(input_text):\n",
    "    sentences = sent_tokenize(input_text)\n",
    "    corrected_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = spelling_tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=spelling_tokenizer.model_max_length)\n",
    "        outputs = spelling_model.generate(**tokens, max_length=spelling_tokenizer.model_max_length)\n",
    "        corrected_sentence = spelling_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "    return ' '.join(corrected_sentences)\n",
    "\n",
    "# Function to correct grammar\n",
    "def correct_grammar(input_text):\n",
    "    tokens = grammar_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=grammar_tokenizer.model_max_length)\n",
    "    outputs = grammar_model.generate(**tokens, max_length=grammar_tokenizer.model_max_length)\n",
    "    return grammar_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Function to correct both spelling and grammar\n",
    "def correct_spelling_and_grammar(input_text):\n",
    "    spelling_corrected = correct_spelling(input_text)\n",
    "    return correct_grammar(spelling_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ba978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input text from file\n",
    "with open('../Data/myvoice_transcription.txt', 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read().strip()\n",
    "\n",
    "# Apply corrections\n",
    "spelling_corrected_text = correct_spelling(input_text)\n",
    "grammar_corrected_text = correct_grammar(input_text)\n",
    "combined_corrected_text = correct_spelling_and_grammar(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b63a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " there don't sien to be any firm ruse above houseman demands correspond to follower accounts is the grantel taquon that the pogram is his early stage and that is still experimenting with the foremad we are continuing to test the payments as we roll up to more creatious and except the twillian san chentel flacture v\n",
      "\n",
      "Spelling corrected text:\n",
      " There don't seem to be any firm rules above houseman demands correspond to follower accounts. is the grantel taquon that the program is his early stage, and that is still experimenting with the foremad. We are continuing to test the payments as we roll up to more creative and except the twillian san chentel flacture. .\n",
      "\n",
      "Grammar corrected text:\n",
      " There don't seem to be any firm ruse above houseman demands correspond to follower accounts is the grantel taquon that the program is his early stage and that is still experimenting with the foremad we are continuing to test the payments as we roll up to more creative and except the twillian san chentel flacture vs. the twillian san chentel.\n",
      "\n",
      "Combined spelling and grammar corrected text:\n",
      " There don't seem to be any firm rules above houseman demands correspond to follower accounts. is the grantel taquon that the program is his early stage, and that is still experimenting with the foremad. We are continuing to test the payments as we roll up to more creative and except the twillian san chentel flacture.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\\n\", input_text)\n",
    "print(\"\\nSpelling corrected text:\\n\", spelling_corrected_text)\n",
    "print(\"\\nGrammar corrected text:\\n\", grammar_corrected_text)\n",
    "print(\"\\nCombined spelling and grammar corrected text:\\n\", combined_corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5ef839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_wer(reference, hypothesis):\n",
    "    r = reference.split()\n",
    "    h = hypothesis.split()\n",
    "    # Building the matrix\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0: \n",
    "                d[0][j] = j\n",
    "            elif j == 0: \n",
    "                d[i][0] = i\n",
    "    # Calculation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    return d[len(r)][len(h)] / float(len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238b9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(reference, hypothesis):\n",
    "    r = reference\n",
    "    h = hypothesis\n",
    "    # Building the matrix\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "    # Calculation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    return d[len(r)][len(h)] / float(len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391d5975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spelling Corrected Text - Word Error Rate: 0.5333333333333333\n",
      "Spelling Corrected Text - Character Error Rate: 0.3159340659340659\n",
      "Grammar Corrected Text - Word Error Rate: 0.55\n",
      "Grammar Corrected Text - Character Error Rate: 0.33516483516483514\n",
      "Combined Corrected Text - Word Error Rate: 0.5333333333333333\n",
      "Combined Corrected Text - Character Error Rate: 0.31868131868131866\n"
     ]
    }
   ],
   "source": [
    "# Read ground truth text from file\n",
    "with open('../Data/ground-truth.txt', 'r', encoding='utf-8') as file:\n",
    "    ground_truth_text = file.read().strip()\n",
    "\n",
    "# Calculate WER and CER for spelling-corrected text\n",
    "spelling_wer = calculate_wer(ground_truth_text, spelling_corrected_text)\n",
    "spelling_cer = calculate_cer(ground_truth_text, spelling_corrected_text)\n",
    "\n",
    "# Calculate WER and CER for grammar-corrected text\n",
    "grammar_wer = calculate_wer(ground_truth_text, grammar_corrected_text)\n",
    "grammar_cer = calculate_cer(ground_truth_text, grammar_corrected_text)\n",
    "\n",
    "# Calculate WER and CER for combined corrected text\n",
    "combined_wer = calculate_wer(ground_truth_text, combined_corrected_text)\n",
    "combined_cer = calculate_cer(ground_truth_text, combined_corrected_text)\n",
    "\n",
    "print(\"Spelling Corrected Text - Word Error Rate:\", spelling_wer)\n",
    "print(\"Spelling Corrected Text - Character Error Rate:\", spelling_cer)\n",
    "print(\"Grammar Corrected Text - Word Error Rate:\", grammar_wer)\n",
    "print(\"Grammar Corrected Text - Character Error Rate:\", grammar_cer)\n",
    "print(\"Combined Corrected Text - Word Error Rate:\", combined_wer)\n",
    "print(\"Combined Corrected Text - Character Error Rate:\", combined_cer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da1d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
