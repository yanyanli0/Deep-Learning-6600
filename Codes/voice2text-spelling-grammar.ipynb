{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363e324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording ...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python asr-1.py record myvoice.wav 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755903fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py play myvoice.wav 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c31b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py transcribe myvoice.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000a522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asr-1.py evaluate myvoice_transcription.txt ground-truth.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6791e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b26ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained spelling correction model and tokenizer\n",
    "spelling_correction = 'oliverguhr/spelling-correction-english-base'\n",
    "spelling_model = AutoModelForSeq2SeqLM.from_pretrained(spelling_correction)\n",
    "spelling_tokenizer = AutoTokenizer.from_pretrained(spelling_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e856d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained grammar correction model and tokenizer\n",
    "grammar_correction = 'vennify/t5-base-grammar-correction'\n",
    "grammar_model = AutoModelForSeq2SeqLM.from_pretrained(grammar_correction)\n",
    "grammar_tokenizer = AutoTokenizer.from_pretrained(grammar_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01fd4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correct spelling\n",
    "def correct_spelling(input_text):\n",
    "    sentences = sent_tokenize(input_text)\n",
    "    corrected_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = spelling_tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=spelling_tokenizer.model_max_length)\n",
    "        outputs = spelling_model.generate(**tokens, max_length=spelling_tokenizer.model_max_length)\n",
    "        corrected_sentence = spelling_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "    return ' '.join(corrected_sentences)\n",
    "\n",
    "# Function to correct grammar\n",
    "def correct_grammar(input_text):\n",
    "    tokens = grammar_tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=grammar_tokenizer.model_max_length)\n",
    "    outputs = grammar_model.generate(**tokens, max_length=grammar_tokenizer.model_max_length)\n",
    "    return grammar_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Function to correct both spelling and grammar\n",
    "def correct_spelling_and_grammar(input_text):\n",
    "    spelling_corrected = correct_spelling(input_text)\n",
    "    return correct_grammar(spelling_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bad73172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input text from file\n",
    "with open('../Data/myvoice_transcription.txt', 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read().strip()\n",
    "\n",
    "# Apply corrections\n",
    "spelling_corrected_text = correct_spelling(input_text)\n",
    "grammar_corrected_text = correct_grammar(input_text)\n",
    "combined_corrected_text = correct_spelling_and_grammar(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29a04e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " there don't seem to be any firm ruse about helphim an accounts correspond to follower accounts instebram tells tacture that the programe is in this early stage and that is still experimenting with the foremat we are continuing to task the payments as we row out to more creators and expect them to flactuate while we are still getting started the\n",
      "\n",
      "Spelling corrected text:\n",
      " There don't seem to be any firm ruse about helphim and accounts correspond to follower accounts. Instagram tells us that the programme is in this early stage and that is still experimenting with the format. We are continuing to task the payments as we row out to more creators and expect them to fluctuate while we are still getting started.\n",
      "\n",
      "Grammar corrected text:\n",
      " The program is in this early stage and that is still experimenting with the program. We are continuing to task the creators and expect them to flactuate while we are still getting started.\n",
      "\n",
      "Combined spelling and grammar corrected text:\n",
      " There doesn't seem to be any firm ruse about helphim and accounts correspond to follower accounts. Instagram tells us that the programme is in this early stage and that is still experimenting with the format. We are continuing to task the payments as we row out to more creators and expect them to fluctuate while we are still getting started.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\\n\", input_text)\n",
    "print(\"\\nSpelling corrected text:\\n\", spelling_corrected_text)\n",
    "print(\"\\nGrammar corrected text:\\n\", grammar_corrected_text)\n",
    "print(\"\\nCombined spelling and grammar corrected text:\\n\", combined_corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7f715c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined corrected text saved to ../Data/myvoice_transcription_corrected.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename\n",
    "output_filename = \"../Data/myvoice_transcription_corrected.txt\"\n",
    "\n",
    "# Save the combined corrected text to a file\n",
    "with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(combined_corrected_text)\n",
    "\n",
    "print(f\"Combined corrected text saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a253c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(reference, hypothesis):\n",
    "    r = reference.split()\n",
    "    h = hypothesis.split()\n",
    "    # Building the matrix\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0: \n",
    "                d[0][j] = j\n",
    "            elif j == 0: \n",
    "                d[i][0] = i\n",
    "    # Calculation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    return d[len(r)][len(h)] / float(len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a638dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(reference, hypothesis):\n",
    "    r = reference\n",
    "    h = hypothesis\n",
    "    # Building the matrix\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "    # Calculation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    return d[len(r)][len(h)] / float(len(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e023c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text - Word Error Rate: 0.5087719298245614\n",
      "Original Text - Character Error Rate: 0.19390581717451524\n",
      "Spelling Corrected Text - Word Error Rate: 0.38333333333333336\n",
      "Spelling Corrected Text - Character Error Rate: 0.18406593406593408\n",
      "Grammar Corrected Text - Word Error Rate: 0.7166666666666667\n",
      "Grammar Corrected Text - Character Error Rate: 0.3489010989010989\n",
      "Combined Corrected Text - Word Error Rate: 0.38333333333333336\n",
      "Combined Corrected Text - Character Error Rate: 0.18956043956043955\n"
     ]
    }
   ],
   "source": [
    "# Read ground truth text from file\n",
    "with open('../Data/ground-truth.txt', 'r', encoding='utf-8') as file:\n",
    "    ground_truth_text = file.read().strip()\n",
    "\n",
    "# Calculate WER and CER for spelling-corrected text\n",
    "spelling_wer = calculate_wer(ground_truth_text, spelling_corrected_text)\n",
    "spelling_cer = calculate_cer(ground_truth_text, spelling_corrected_text)\n",
    "\n",
    "# Calculate WER and CER for grammar-corrected text\n",
    "grammar_wer = calculate_wer(ground_truth_text, grammar_corrected_text)\n",
    "grammar_cer = calculate_cer(ground_truth_text, grammar_corrected_text)\n",
    "\n",
    "# Calculate WER and CER for combined corrected text\n",
    "combined_wer = calculate_wer(ground_truth_text, combined_corrected_text)\n",
    "combined_cer = calculate_cer(ground_truth_text, combined_corrected_text)\n",
    "\n",
    "# Read WER and CER from results.json\n",
    "with open('../Data/results.json', 'r', encoding='utf-8') as file:\n",
    "    results_data = json.load(file)\n",
    "\n",
    "original_wer = results_data.get(\"word_error_rate\", \"Not available\")\n",
    "original_cer = results_data.get(\"character_error_rate\", \"Not available\")\n",
    "\n",
    "# Print WER and CER for each type of corrected text\n",
    "print(\"Original Text - Word Error Rate:\", original_wer)\n",
    "print(\"Original Text - Character Error Rate:\", original_cer)\n",
    "print(\"Spelling Corrected Text - Word Error Rate:\", spelling_wer)\n",
    "print(\"Spelling Corrected Text - Character Error Rate:\", spelling_cer)\n",
    "print(\"Grammar Corrected Text - Word Error Rate:\", grammar_wer)\n",
    "print(\"Grammar Corrected Text - Character Error Rate:\", grammar_cer)\n",
    "print(\"Combined Corrected Text - Word Error Rate:\", combined_wer)\n",
    "print(\"Combined Corrected Text - Character Error Rate:\", combined_cer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021d504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
